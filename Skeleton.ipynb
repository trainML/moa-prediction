{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source material: https://www.kaggle.com/nicohrubec/pytorch-multilabel-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = os.environ.get('TRAINML_DATA_PATH') if os.environ.get('TRAINML_DATA_PATH') else '../input/lish-moa'\n",
    "BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(f'{BASE_PATH}/train_features.csv')\n",
    "train_targets = pd.read_csv(f'{BASE_PATH}/train_targets_scored.csv')\n",
    "test_features = pd.read_csv(f'{BASE_PATH}/test_features.csv')\n",
    "\n",
    "sample_submission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>-0.0636</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.5080</td>\n",
       "      <td>-0.4713</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>-0.8121</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>-0.3246</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.3260</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.3743</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>-0.7178</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>-0.3195</td>\n",
       "      <td>-0.8086</td>\n",
       "      <td>-0.9798</td>\n",
       "      <td>-0.2084</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>-0.2715</td>\n",
       "      <td>0.3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>ctl_vehicle</td>\n",
       "      <td>48</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>0.3756</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>-0.7389</td>\n",
       "      <td>0.5505</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.7592</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1105</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>-0.2012</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>1.5230</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>-0.6290</td>\n",
       "      <td>0.0740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>-0.1361</td>\n",
       "      <td>0.7952</td>\n",
       "      <td>-0.3611</td>\n",
       "      <td>-3.6750</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3890</td>\n",
       "      <td>-1.7450</td>\n",
       "      <td>-6.6300</td>\n",
       "      <td>-4.0950</td>\n",
       "      <td>-7.3860</td>\n",
       "      <td>-1.4160</td>\n",
       "      <td>-3.5770</td>\n",
       "      <td>-0.4775</td>\n",
       "      <td>-2.1500</td>\n",
       "      <td>-4.2520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id      cp_type  cp_time cp_dose     g-0     g-1     g-2  \\\n",
       "0      id_000644bb2       trt_cp       24      D1  1.0620  0.5577 -0.2479   \n",
       "1      id_000779bfc       trt_cp       72      D1  0.0743  0.4087  0.2991   \n",
       "2      id_000a6266a       trt_cp       48      D1  0.6280  0.5817  1.5540   \n",
       "3      id_0015fd391       trt_cp       48      D1 -0.5138 -0.2491 -0.2656   \n",
       "4      id_001626bd3       trt_cp       72      D2 -0.3254 -0.4009  0.9700   \n",
       "...             ...          ...      ...     ...     ...     ...     ...   \n",
       "23809  id_fffb1ceed       trt_cp       24      D2  0.1394 -0.0636 -0.1112   \n",
       "23810  id_fffb70c0c       trt_cp       24      D2 -1.3260  0.3478 -0.3743   \n",
       "23811  id_fffc1c3f4  ctl_vehicle       48      D2  0.3942  0.3756  0.3109   \n",
       "23812  id_fffcb9e7c       trt_cp       24      D1  0.6660  0.2324  0.4392   \n",
       "23813  id_ffffdd77b       trt_cp       72      D1 -0.8598  1.0240 -0.1361   \n",
       "\n",
       "          g-3     g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94  \\\n",
       "0     -0.6208 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912   \n",
       "1      0.0604  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957   \n",
       "2     -0.0764 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240   \n",
       "3      0.5288  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632   \n",
       "4      0.6919  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523   \n",
       "...       ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "23809 -0.5080 -0.4713  0.7201  ...  0.1969  0.0262 -0.8121  0.3434  0.5372   \n",
       "23810  0.9905 -0.7178  0.6621  ...  0.4286  0.4426  0.0423 -0.3195 -0.8086   \n",
       "23811 -0.7389  0.5505 -0.0159  ...  0.5409  0.3755  0.7343  0.2807  0.4116   \n",
       "23812  0.2044  0.8531 -0.0343  ... -0.1105  0.4258 -0.2012  0.1506  1.5230   \n",
       "23813  0.7952 -0.3611 -3.6750  ... -3.3890 -1.7450 -6.6300 -4.0950 -7.3860   \n",
       "\n",
       "         c-95    c-96    c-97    c-98    c-99  \n",
       "0      0.6584 -0.3981  0.2139  0.3801  0.4176  \n",
       "1      0.4899  0.1522  0.1241  0.6077  0.7371  \n",
       "2     -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "3     -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "4     -0.3031  0.1094  0.2885 -0.3786  0.7125  \n",
       "...       ...     ...     ...     ...     ...  \n",
       "23809 -0.3246  0.0631  0.9171  0.5258  0.4680  \n",
       "23810 -0.9798 -0.2084 -0.1224 -0.2715  0.3689  \n",
       "23811  0.6422  0.2256  0.7592  0.6656  0.3808  \n",
       "23812  0.7101  0.1732  0.7015 -0.6290  0.0740  \n",
       "23813 -1.4160 -3.5770 -0.4775 -2.1500 -4.2520  \n",
       "\n",
       "[23814 rows x 876 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                               0  ...                                      0   \n",
       "1                               0  ...                                      0   \n",
       "2                               0  ...                                      0   \n",
       "3                               0  ...                                      0   \n",
       "4                               0  ...                                      0   \n",
       "...                           ...  ...                                    ...   \n",
       "23809                           0  ...                                      0   \n",
       "23810                           0  ...                                      0   \n",
       "23811                           0  ...                                      0   \n",
       "23812                           0  ...                                      0   \n",
       "23813                           0  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "train_data = preprocess(train_features)\n",
    "test_data = preprocess(test_features)\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "train_targets = train_targets.loc[train_data['cp_type']==0].reset_index(drop=True)\n",
    "train_data = train_data.loc[train_data['cp_type']==0].reset_index(drop=True)\n",
    "\n",
    "X = train_data.values\n",
    "Y = train_targets.values\n",
    "X_test = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    , 24.    ,  0.    , ...,  0.2139,  0.3801,  0.4176],\n",
       "       [ 0.    , 72.    ,  0.    , ...,  0.1241,  0.6077,  0.7371],\n",
       "       [ 0.    , 48.    ,  0.    , ..., -0.2187, -1.408 ,  0.6931],\n",
       "       ...,\n",
       "       [ 0.    , 24.    ,  1.    , ..., -0.1224, -0.2715,  0.3689],\n",
       "       [ 0.    , 24.    ,  0.    , ...,  0.7015, -0.629 ,  0.074 ],\n",
       "       [ 0.    , 72.    ,  0.    , ..., -0.4775, -2.15  , -4.252 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.000e+00,  2.400e+01,  0.000e+00, ..., -5.020e-02,  1.510e-01,\n",
       "        -7.750e-01],\n",
       "       [ 0.000e+00,  7.200e+01,  0.000e+00, ..., -4.764e-01, -1.381e+00,\n",
       "        -7.300e-01],\n",
       "       [ 1.000e+00,  2.400e+01,  0.000e+00, ...,  1.016e+00,  4.924e-01,\n",
       "        -1.942e-01],\n",
       "       ...,\n",
       "       [ 0.000e+00,  7.200e+01,  0.000e+00, ...,  5.888e-01, -4.205e-01,\n",
       "        -1.504e-01],\n",
       "       [ 0.000e+00,  4.800e+01,  1.000e+00, ...,  5.074e-01,  7.430e-01,\n",
       "        -4.840e-02],\n",
       "       [ 0.000e+00,  7.200e+01,  0.000e+00, ...,  7.570e-02, -1.356e-01,\n",
       "         5.280e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, features, targets, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data = features\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.data[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'eval':\n",
    "            return torch.FloatTensor(self.data[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MoaDataset(X_train, y_train)\n",
    "val_dataset = MoaDataset(X_val, y_val)\n",
    "test_dataset = MoaDataset(X_test, None, mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.batch_norm1(X)\n",
    "        X = self.dropout1(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        \n",
    "        X = self.batch_norm2(X)\n",
    "        X = self.dropout2(X)\n",
    "        X = F.relu(self.dense2(X))\n",
    "        \n",
    "        X = self.batch_norm3(X)\n",
    "        X = self.dropout3(X)\n",
    "        X = torch.sigmoid(self.dense3(X))\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, train_loader, val_loader, epochs):\n",
    "  train_losses = np.zeros(epochs)\n",
    "  val_losses = np.zeros(epochs)\n",
    "  for it in range(epochs):\n",
    "    t0 = datetime.now()\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for inputs, targets in train_loader:\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      train_loss.append(loss.item() / len(train_loader))\n",
    "    \n",
    "    train_loss = np.mean(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    for inputs, targets in val_loader:\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "      val_loss.append(loss.item() / len(val_loader))\n",
    "    val_loss = np.mean(val_loss)\n",
    "\n",
    "    train_losses[it] = train_loss\n",
    "    val_losses[it] = val_loss\n",
    "\n",
    "    dt = datetime.now() - t0\n",
    "    print(f\"Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Duration {dt}\")\n",
    "\n",
    "  return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoaModel(\n",
       "  (batch_norm1): BatchNorm1d(875, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (dense1): Linear(in_features=875, out_features=2048, bias=True)\n",
       "  (batch_norm2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (dense2): Linear(in_features=2048, out_features=1048, bias=True)\n",
       "  (batch_norm3): BatchNorm1d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       "  (dense3): Linear(in_features=1048, out_features=206, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MoaModel(train_data.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.1870, Validation Loss: 0.3647, Duration 0:00:00.615799\n",
      "Epoch 2/50, Train Loss: 0.1802, Validation Loss: 0.3506, Duration 0:00:00.594556\n",
      "Epoch 3/50, Train Loss: 0.1776, Validation Loss: 0.3447, Duration 0:00:00.517748\n",
      "Epoch 4/50, Train Loss: 0.1755, Validation Loss: 0.3373, Duration 0:00:00.618606\n",
      "Epoch 5/50, Train Loss: 0.1716, Validation Loss: 0.3247, Duration 0:00:00.589045\n",
      "Epoch 6/50, Train Loss: 0.1665, Validation Loss: 0.3105, Duration 0:00:00.589430\n",
      "Epoch 7/50, Train Loss: 0.1603, Validation Loss: 0.2969, Duration 0:00:00.588694\n",
      "Epoch 8/50, Train Loss: 0.1522, Validation Loss: 0.2802, Duration 0:00:00.518920\n",
      "Epoch 9/50, Train Loss: 0.1424, Validation Loss: 0.2602, Duration 0:00:00.600598\n",
      "Epoch 10/50, Train Loss: 0.1314, Validation Loss: 0.2385, Duration 0:00:00.589076\n",
      "Epoch 11/50, Train Loss: 0.1195, Validation Loss: 0.2162, Duration 0:00:00.589629\n",
      "Epoch 12/50, Train Loss: 0.1073, Validation Loss: 0.1895, Duration 0:00:00.518501\n",
      "Epoch 13/50, Train Loss: 0.0960, Validation Loss: 0.1734, Duration 0:00:00.592984\n",
      "Epoch 14/50, Train Loss: 0.0860, Validation Loss: 0.1534, Duration 0:00:00.590303\n",
      "Epoch 15/50, Train Loss: 0.0761, Validation Loss: 0.1353, Duration 0:00:00.598318\n",
      "Epoch 16/50, Train Loss: 0.0681, Validation Loss: 0.1309, Duration 0:00:00.590188\n",
      "Epoch 17/50, Train Loss: 0.0604, Validation Loss: 0.1078, Duration 0:00:00.519643\n",
      "Epoch 18/50, Train Loss: 0.0538, Validation Loss: 0.0957, Duration 0:00:00.595121\n",
      "Epoch 19/50, Train Loss: 0.0490, Validation Loss: 0.0878, Duration 0:00:00.591979\n",
      "Epoch 20/50, Train Loss: 0.0442, Validation Loss: 0.0801, Duration 0:00:00.593430\n",
      "Epoch 21/50, Train Loss: 0.0412, Validation Loss: 0.0776, Duration 0:00:00.595542\n",
      "Epoch 22/50, Train Loss: 0.0395, Validation Loss: 0.0684, Duration 0:00:00.520597\n",
      "Epoch 23/50, Train Loss: 0.0342, Validation Loss: 0.0603, Duration 0:00:00.588743\n",
      "Epoch 24/50, Train Loss: 0.0322, Validation Loss: 0.0602, Duration 0:00:00.589991\n",
      "Epoch 25/50, Train Loss: 0.0295, Validation Loss: 0.0554, Duration 0:00:00.588704\n",
      "Epoch 26/50, Train Loss: 0.0274, Validation Loss: 0.0508, Duration 0:00:00.600267\n",
      "Epoch 27/50, Train Loss: 0.0270, Validation Loss: 0.0463, Duration 0:00:00.517962\n",
      "Epoch 28/50, Train Loss: 0.0240, Validation Loss: 0.0439, Duration 0:00:00.592494\n",
      "Epoch 29/50, Train Loss: 0.0223, Validation Loss: 0.0412, Duration 0:00:00.588416\n",
      "Epoch 30/50, Train Loss: 0.0210, Validation Loss: 0.0396, Duration 0:00:00.590936\n",
      "Epoch 31/50, Train Loss: 0.0196, Validation Loss: 0.0372, Duration 0:00:00.589284\n",
      "Epoch 32/50, Train Loss: 0.0186, Validation Loss: 0.0344, Duration 0:00:00.524955\n",
      "Epoch 33/50, Train Loss: 0.0179, Validation Loss: 0.0331, Duration 0:00:00.590143\n",
      "Epoch 34/50, Train Loss: 0.0173, Validation Loss: 0.0325, Duration 0:00:00.588438\n",
      "Epoch 35/50, Train Loss: 0.0165, Validation Loss: 0.0322, Duration 0:00:00.596997\n",
      "Epoch 36/50, Train Loss: 0.0157, Validation Loss: 0.0303, Duration 0:00:00.518318\n",
      "Epoch 37/50, Train Loss: 0.0147, Validation Loss: 0.0273, Duration 0:00:00.600560\n",
      "Epoch 38/50, Train Loss: 0.0142, Validation Loss: 0.0263, Duration 0:00:00.595419\n",
      "Epoch 39/50, Train Loss: 0.0138, Validation Loss: 0.0264, Duration 0:00:00.595556\n",
      "Epoch 40/50, Train Loss: 0.0132, Validation Loss: 0.0252, Duration 0:00:00.591738\n",
      "Epoch 41/50, Train Loss: 0.0128, Validation Loss: 0.0239, Duration 0:00:00.517774\n",
      "Epoch 42/50, Train Loss: 0.0121, Validation Loss: 0.0225, Duration 0:00:00.593007\n",
      "Epoch 43/50, Train Loss: 0.0121, Validation Loss: 0.0221, Duration 0:00:00.607227\n",
      "Epoch 44/50, Train Loss: 0.0116, Validation Loss: 0.0224, Duration 0:00:00.591340\n",
      "Epoch 45/50, Train Loss: 0.0112, Validation Loss: 0.0218, Duration 0:00:00.591161\n",
      "Epoch 46/50, Train Loss: 0.0110, Validation Loss: 0.0209, Duration 0:00:00.520416\n",
      "Epoch 47/50, Train Loss: 0.0106, Validation Loss: 0.0200, Duration 0:00:00.591558\n",
      "Epoch 48/50, Train Loss: 0.0103, Validation Loss: 0.0194, Duration 0:00:00.600062\n",
      "Epoch 49/50, Train Loss: 0.0102, Validation Loss: 0.0190, Duration 0:00:00.597745\n",
      "Epoch 50/50, Train Loss: 0.0105, Validation Loss: 0.0190, Duration 0:00:00.590547\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = batch_gd(model, criterion, optimizer, train_loader, val_loader, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02479033, 0.02448333, 0.02440468, ..., 0.02429675, 0.02458981,\n",
       "        0.02612645],\n",
       "       [0.02620283, 0.02601224, 0.02650359, ..., 0.02601493, 0.02675914,\n",
       "        0.02818297],\n",
       "       [0.0104325 , 0.00928143, 0.00973123, ..., 0.00948484, 0.00948824,\n",
       "        0.00999806],\n",
       "       ...,\n",
       "       [0.0241422 , 0.02337634, 0.02410814, ..., 0.02374226, 0.02440455,\n",
       "        0.02556291],\n",
       "       [0.02571984, 0.02526503, 0.02540918, ..., 0.02572037, 0.02561725,\n",
       "        0.0270779 ],\n",
       "       [0.02457236, 0.02424092, 0.02448655, ..., 0.02438006, 0.02474346,\n",
       "        0.026087  ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [col for col in train_targets.columns]\n",
    "sample_submission[targets] = preds\n",
    "sample_submission.loc[test_features['cp_type']=='ctl_vehicle', targets] = 0\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.024790</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>0.024405</td>\n",
       "      <td>0.026103</td>\n",
       "      <td>0.028710</td>\n",
       "      <td>0.024767</td>\n",
       "      <td>0.025516</td>\n",
       "      <td>0.026518</td>\n",
       "      <td>0.024287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025557</td>\n",
       "      <td>0.025959</td>\n",
       "      <td>0.022953</td>\n",
       "      <td>0.029317</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>0.026817</td>\n",
       "      <td>0.026760</td>\n",
       "      <td>0.024297</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>0.026126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.026203</td>\n",
       "      <td>0.026012</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.025877</td>\n",
       "      <td>0.028017</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.027185</td>\n",
       "      <td>0.028379</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027650</td>\n",
       "      <td>0.027721</td>\n",
       "      <td>0.024316</td>\n",
       "      <td>0.029529</td>\n",
       "      <td>0.027160</td>\n",
       "      <td>0.028929</td>\n",
       "      <td>0.028806</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>0.026759</td>\n",
       "      <td>0.028183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.026220</td>\n",
       "      <td>0.026083</td>\n",
       "      <td>0.026519</td>\n",
       "      <td>0.026025</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.026988</td>\n",
       "      <td>0.027209</td>\n",
       "      <td>0.028106</td>\n",
       "      <td>0.026321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027728</td>\n",
       "      <td>0.028009</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.039367</td>\n",
       "      <td>0.027582</td>\n",
       "      <td>0.028995</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.026227</td>\n",
       "      <td>0.026909</td>\n",
       "      <td>0.028319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.025064</td>\n",
       "      <td>0.023851</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>0.027649</td>\n",
       "      <td>0.029717</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.026066</td>\n",
       "      <td>0.025812</td>\n",
       "      <td>0.024075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>0.025211</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>0.020271</td>\n",
       "      <td>0.022299</td>\n",
       "      <td>0.026357</td>\n",
       "      <td>0.022074</td>\n",
       "      <td>0.024546</td>\n",
       "      <td>0.024911</td>\n",
       "      <td>0.026267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.025911</td>\n",
       "      <td>0.026206</td>\n",
       "      <td>0.027623</td>\n",
       "      <td>0.025821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026807</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.045978</td>\n",
       "      <td>0.027195</td>\n",
       "      <td>0.028468</td>\n",
       "      <td>0.031158</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.027510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.024831</td>\n",
       "      <td>0.023817</td>\n",
       "      <td>0.024079</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>0.031995</td>\n",
       "      <td>0.024586</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.023619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.016815</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.025982</td>\n",
       "      <td>0.021916</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.024291</td>\n",
       "      <td>0.025582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.024142</td>\n",
       "      <td>0.023376</td>\n",
       "      <td>0.024108</td>\n",
       "      <td>0.025202</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>0.025249</td>\n",
       "      <td>0.025419</td>\n",
       "      <td>0.025891</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.024646</td>\n",
       "      <td>0.021856</td>\n",
       "      <td>0.018575</td>\n",
       "      <td>0.022820</td>\n",
       "      <td>0.025969</td>\n",
       "      <td>0.022374</td>\n",
       "      <td>0.023742</td>\n",
       "      <td>0.024405</td>\n",
       "      <td>0.025563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.025720</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>0.025409</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>0.030335</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.027053</td>\n",
       "      <td>0.026874</td>\n",
       "      <td>0.025266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>0.024418</td>\n",
       "      <td>0.034518</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.027441</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.025720</td>\n",
       "      <td>0.025617</td>\n",
       "      <td>0.027078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.024572</td>\n",
       "      <td>0.024241</td>\n",
       "      <td>0.024487</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>0.025669</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.024130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.025851</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>0.026680</td>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.024380</td>\n",
       "      <td>0.024743</td>\n",
       "      <td>0.026087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.024790                0.024483   \n",
       "1     id_001897cda                     0.026203                0.026012   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.026220                0.026083   \n",
       "4     id_0027f1083                     0.025064                0.023851   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.025889                0.025926   \n",
       "3978  id_ff925dd0d                     0.024831                0.023817   \n",
       "3979  id_ffb710450                     0.024142                0.023376   \n",
       "3980  id_ffbb869f2                     0.025720                0.025265   \n",
       "3981  id_ffd5800b6                     0.024572                0.024241   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.024405                        0.026103   \n",
       "1           0.026504                        0.025877   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.026519                        0.026025   \n",
       "4           0.024688                        0.027649   \n",
       "...              ...                             ...   \n",
       "3977        0.025621                        0.026100   \n",
       "3978        0.024079                        0.026960   \n",
       "3979        0.024108                        0.025202   \n",
       "3980        0.025409                        0.027058   \n",
       "3981        0.024487                        0.025328   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.028710                        0.024767   \n",
       "1                              0.028017                        0.027372   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.027427                        0.026988   \n",
       "4                              0.029717                        0.024900   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.026826                        0.025911   \n",
       "3978                           0.031995                        0.024586   \n",
       "3979                           0.029288                        0.025249   \n",
       "3980                           0.030335                        0.024862   \n",
       "3981                           0.028400                        0.025173   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.025516                       0.026518   \n",
       "1                       0.027185                       0.028379   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.027209                       0.028106   \n",
       "4                       0.026066                       0.025812   \n",
       "...                          ...                            ...   \n",
       "3977                    0.026206                       0.027623   \n",
       "3978                    0.025901                       0.025996   \n",
       "3979                    0.025419                       0.025891   \n",
       "3980                    0.027053                       0.026874   \n",
       "3981                    0.025669                       0.026419   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.024287  ...                               0.025557   \n",
       "1                       0.026214  ...                               0.027650   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.026321  ...                               0.027728   \n",
       "4                       0.024075  ...                               0.025746   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.025821  ...                               0.026807   \n",
       "3978                    0.023619  ...                               0.025133   \n",
       "3979                    0.023501  ...                               0.025126   \n",
       "3980                    0.025266  ...                               0.026513   \n",
       "3981                    0.024130  ...                               0.025700   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.025959         0.022953           0.029317   \n",
       "1         0.027721         0.024316           0.029529   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.028009         0.024750           0.039367   \n",
       "4         0.025211         0.022678           0.020271   \n",
       "...            ...              ...                ...   \n",
       "3977      0.027848         0.024134           0.045978   \n",
       "3978      0.024778         0.022242           0.016815   \n",
       "3979      0.024646         0.021856           0.018575   \n",
       "3980      0.027172         0.024418           0.034518   \n",
       "3981      0.025851         0.022734           0.027232   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.024453                               0.026817   \n",
       "1                      0.027160                               0.028929   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.027582                               0.028995   \n",
       "4                      0.022299                               0.026357   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.027195                               0.028468   \n",
       "3978                   0.021938                               0.025982   \n",
       "3979                   0.022820                               0.025969   \n",
       "3980                   0.025340                               0.027441   \n",
       "3981                   0.024039                               0.026680   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.026760   0.024297                    0.024590       0.026126  \n",
       "1            0.028806   0.026015                    0.026759       0.028183  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.029438   0.026227                    0.026909       0.028319  \n",
       "4            0.022074   0.024546                    0.024911       0.026267  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.031158   0.025393                    0.025732       0.027510  \n",
       "3978         0.021916   0.024063                    0.024291       0.025582  \n",
       "3979         0.022374   0.023742                    0.024405       0.025563  \n",
       "3980         0.026471   0.025720                    0.025617       0.027078  \n",
       "3981         0.025499   0.024380                    0.024743       0.026087  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neuropeptide_receptor_antagonist</th>\n",
       "      <td>82.452950</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppar_receptor_antagonist</th>\n",
       "      <td>83.338545</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <td>83.508734</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monopolar_spindle_1_kinase_inhibitor</th>\n",
       "      <td>85.337615</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cholinergic_receptor_antagonist</th>\n",
       "      <td>85.541539</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dopamine_receptor_antagonist</th>\n",
       "      <td>114.058512</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdk_inhibitor</th>\n",
       "      <td>118.585020</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <td>120.738788</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proteasome_inhibitor</th>\n",
       "      <td>221.500491</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfkb_inhibitor</th>\n",
       "      <td>222.851475</td>\n",
       "      <td>3982.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sum   count\n",
       "neuropeptide_receptor_antagonist       82.452950  3982.0\n",
       "ppar_receptor_antagonist               83.338545  3982.0\n",
       "trpv_antagonist                        83.508734  3982.0\n",
       "monopolar_spindle_1_kinase_inhibitor   85.337615  3982.0\n",
       "cholinergic_receptor_antagonist        85.541539  3982.0\n",
       "...                                          ...     ...\n",
       "dopamine_receptor_antagonist          114.058512  3982.0\n",
       "cdk_inhibitor                         118.585020  3982.0\n",
       "tubulin_inhibitor                     120.738788  3982.0\n",
       "proteasome_inhibitor                  221.500491  3982.0\n",
       "nfkb_inhibitor                        222.851475  3982.0\n",
       "\n",
       "[206 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission_summary = sample_submission[sample_submission.columns[~sample_submission.columns.isin(['sig_id'])]].T.agg(['sum','count'], axis='columns').sort_values(by=['sum'])\n",
    "sample_submission_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
