{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iterstrat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4ecf91398ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0miterstrat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_stratifiers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultilabelStratifiedKFold\u001b[0m  \u001b[0;31m# trainML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'iterstrat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4ecf91398ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/iterative-stratification\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0miterstrat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_stratifiers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultilabelStratifiedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'iterstrat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "try:\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold  # trainML\n",
    "except:\n",
    "    sys.path.append(\"../input/iterative-stratification\")  # kaggle\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/data'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = os.environ.get('TRAINML_DATA_PATH') if os.environ.get('TRAINML_DATA_PATH') else '../input/lish-moa'\n",
    "BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(f'{BASE_PATH}/train_features.csv')\n",
    "train_targets = pd.read_csv(f'{BASE_PATH}/train_targets_scored.csv')\n",
    "test_features = pd.read_csv(f'{BASE_PATH}/test_features.csv')\n",
    "\n",
    "sample_submission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "train_data = preprocess(train_features)\n",
    "test_data = preprocess(test_features)\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "train_targets = train_targets.loc[train_data['cp_type']==0].reset_index(drop=True)\n",
    "train_data = train_data.loc[train_data['cp_type']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "def get_tail_labels(df: pd.DataFrame, ql=[0.03, 1.]) -> list:\n",
    "    \" Find the underepresented targets a.k.a. minority labels. \"\n",
    "    irlbl = df.sum(axis=0)\n",
    "    irlbl = irlbl[(irlbl > irlbl.quantile(ql[0])) & ((irlbl < irlbl.quantile(ql[1])))]  # Filtering\n",
    "    irlbl = irlbl.max() / irlbl\n",
    "    threshold_irlbl = irlbl.median()\n",
    "    tail_labels = irlbl[irlbl > threshold_irlbl].index.tolist()\n",
    "    return tail_labels\n",
    "\n",
    "def get_minority_samples(X: pd.DataFrame, y: pd.DataFrame, ql=[0.03, 1.]):\n",
    "    \" Find minority samples associated with minority labels. \"\n",
    "    tail_labels = get_tail_labels(y, ql=ql)\n",
    "    index = y[y[tail_labels].apply(lambda x: (x == 1).any(), axis=1)].index.tolist()\n",
    "    \n",
    "    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n",
    "    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n",
    "    return X_sub, y_sub\n",
    "\n",
    "def nearest_neighbour(X: pd.DataFrame, neigh) -> list:\n",
    "    \" Find nearest neighbors for each sample in X dataframe. \"\n",
    "    nbs = NearestNeighbors(n_neighbors=neigh, metric='euclidean', algorithm='kd_tree').fit(X)\n",
    "    euclidean, indices = nbs.kneighbors(X)\n",
    "    return indices\n",
    "\n",
    "def MLSMOTE(X, y, n_samples, n_neighbors=5):\n",
    "    \" Generate new samples using MLSMOTE algorithm. \"\n",
    "    indices2 = nearest_neighbour(X, neigh=n_neighbors)\n",
    "    n = len(indices2)\n",
    "    new_X = np.zeros((n_samples, X.shape[1]))\n",
    "    target = np.zeros((n_samples, y.shape[1]))\n",
    "    for i in range(n_samples):\n",
    "        reference = random.randint(0, n-1)\n",
    "        neighbor = random.choice(indices2[reference, 1:])\n",
    "        all_point = indices2[reference]\n",
    "        nn_df = y[y.index.isin(all_point)]\n",
    "        ser = nn_df.sum(axis = 0, skipna = True)\n",
    "        target[i] = np.array([1 if val > 0 else 0 for val in ser])\n",
    "        ratio = random.random()\n",
    "        gap = X.loc[reference,:] - X.loc[neighbor,:]\n",
    "        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n",
    "    new_X = pd.DataFrame(new_X, columns=X.columns)\n",
    "    target = pd.DataFrame(target, columns=y.columns)\n",
    "    return new_X, target\n",
    "\n",
    "def augment_data(X, y, oversample_args: tuple):\n",
    "    \" Augment feature/targets data (just doing oversampling for now)\"\n",
    "    n_samples, n_neighbors = oversample_args\n",
    "\n",
    "    X_sub, y_sub = get_minority_samples(X, y)\n",
    "    X_res, y_res = MLSMOTE(X_sub, y_sub, n_samples, n_neighbors)\n",
    "    X_augmented = pd.concat([X, X_res])\n",
    "    y_augmented = pd.concat([y, y_res])\n",
    "    return X_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oversample_args = (1000, 5)\n",
    "train_data_augmented, train_targets_augmented = augment_data(train_data, train_targets, data_oversample_args)\n",
    "\n",
    "X = train_data_augmented.values\n",
    "Y = train_targets_augmented.values\n",
    "X_test = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_columns,\n",
    "        model_state=None,\n",
    "        layer1_outputs=2048,\n",
    "        layer1_dropout=0.2,\n",
    "        layer2_outputs=1048,\n",
    "        layer2_dropout=0.5,\n",
    "        layer3_enable=False,\n",
    "        layer3_outputs=None,\n",
    "        layer3_dropout=0.5,\n",
    "        final_layer_dropout=0.5,\n",
    "    ):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(layer1_dropout)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, layer1_outputs))\n",
    "\n",
    "        self.batch_norm2 = nn.BatchNorm1d(layer1_outputs)\n",
    "        self.dropout2 = nn.Dropout(layer2_dropout)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(layer1_outputs, layer2_outputs))\n",
    "\n",
    "        self.layer3 = layer3_enable\n",
    "        if self.layer3:\n",
    "            self.batch_norm3 = nn.BatchNorm1d(layer2_outputs)\n",
    "            self.dropout3 = nn.Dropout(layer3_dropout)\n",
    "            self.dense3 = nn.utils.weight_norm(\n",
    "                nn.Linear(layer2_outputs, layer3_outputs)\n",
    "            )\n",
    "\n",
    "        final_layer_inputs = layer3_outputs if self.layer3 else layer2_outputs\n",
    "        self.batch_norm_final = nn.BatchNorm1d(final_layer_inputs)\n",
    "        self.dropout_final = nn.Dropout(final_layer_dropout)\n",
    "        self.dense_final = nn.utils.weight_norm(nn.Linear(final_layer_inputs, 206))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.batch_norm1(X)\n",
    "        X = self.dropout1(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "\n",
    "        X = self.batch_norm2(X)\n",
    "        X = self.dropout2(X)\n",
    "        X = F.relu(self.dense2(X))\n",
    "\n",
    "        if self.layer3:\n",
    "            X = self.batch_norm3(X)\n",
    "            X = self.dropout3(X)\n",
    "            X = F.relu(self.dense3(X))\n",
    "\n",
    "        X = self.batch_norm_final(X)\n",
    "        X = self.dropout_final(X)\n",
    "        X = F.sigmoid(self.dense_final(X))\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _load_from_file(self, file):\n",
    "        self.load_state_dict(torch.load(file))\n",
    "\n",
    "    def save(self, file):\n",
    "        torch.save(self.state_dict(), file)\n",
    "\n",
    "\n",
    "def batch_gd(model, device, criterion, optimizer, train_loader, val_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    val_losses = np.zeros(epochs)\n",
    "    for it in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item() / len(train_loader))\n",
    "\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss.append(loss.item() / len(val_loader))\n",
    "        val_loss = np.mean(val_loss)\n",
    "\n",
    "        train_losses[it] = train_loss\n",
    "        val_losses[it] = val_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(\n",
    "            f\"Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Duration {dt}\"\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "def predict(model, device, data_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for inputs, _ in data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, features, targets, mode=\"train\"):\n",
    "        self.mode = mode\n",
    "        self.data = features\n",
    "        if mode == \"train\":\n",
    "            self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"train\":\n",
    "            return torch.FloatTensor(self.data[idx]), torch.FloatTensor(\n",
    "                self.targets[idx]\n",
    "            )\n",
    "        elif self.mode == \"eval\":\n",
    "            return torch.FloatTensor(self.data[idx]), 0\n",
    "\n",
    "\n",
    "def train(model, device, X, Y, n_splits=10, batch_size=4096, epochs=50):\n",
    "    kfold = MultilabelStratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    train_losses = np.array([])\n",
    "    val_losses = np.array([])\n",
    "\n",
    "    for n, (tr, te) in enumerate(kfold.split(X, Y)):\n",
    "        X_train, X_val = X[tr], X[te]\n",
    "        y_train, y_val = Y[tr], Y[te]\n",
    "\n",
    "        train_dataset = MoaDataset(X_train, y_train)\n",
    "        val_dataset = MoaDataset(X_val, y_val)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            dataset=train_dataset, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            dataset=val_dataset, batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "        split_train_losses, split_val_losses = batch_gd(\n",
    "            model, device, criterion, optimizer, train_loader, val_loader, epochs\n",
    "        )\n",
    "        print(\n",
    "            f\"Fold {n+1}, final train loss: {split_train_losses[epochs-1]:5.5f}, final train loss: {split_val_losses[epochs-1]:5.5f}\"\n",
    "        )\n",
    "        train_losses = np.concatenate((train_losses, split_train_losses))\n",
    "        val_losses = np.concatenate((val_losses, split_val_losses))\n",
    "\n",
    "    model.save(\"latest_model\")\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoaModel(\n",
       "  (batch_norm1): BatchNorm1d(875, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (dense1): Linear(in_features=875, out_features=2048, bias=True)\n",
       "  (batch_norm2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (dense2): Linear(in_features=2048, out_features=1048, bias=True)\n",
       "  (batch_norm_final): BatchNorm1d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout_final): Dropout(p=0.5, inplace=False)\n",
       "  (dense_final): Linear(in_features=1048, out_features=206, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MoaModel(train_data.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultilabelStratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-120a79ce00a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-aad3d95d7498>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, X, Y, n_splits, batch_size, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultilabelStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultilabelStratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size=4096\n",
    "n_splits=10\n",
    "epochs=50\n",
    "train_losses, val_losses = train(model, device, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MoaDataset(X_test, None, mode='eval')\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "preds = predict(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [col for col in train_targets.columns]\n",
    "sample_submission[targets] = preds\n",
    "sample_submission.loc[test_features['cp_type']=='ctl_vehicle', targets] = 0\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
