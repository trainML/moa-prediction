{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from autoPyTorch import AutoNetMultilabel\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import json\n",
    "try:\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold  # trainML\n",
    "except:\n",
    "    sys.path.append(\"../input/iterative-stratification\")  # kaggle\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = os.environ.get('TRAINML_DATA_PATH') if os.environ.get('TRAINML_DATA_PATH') else '../input/lish-moa'\n",
    "BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(f'{BASE_PATH}/train_features.csv')\n",
    "train_targets = pd.read_csv(f'{BASE_PATH}/train_targets_scored.csv')\n",
    "test_features = pd.read_csv(f'{BASE_PATH}/test_features.csv')\n",
    "\n",
    "sample_submission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "train_data = preprocess(train_features)\n",
    "test_data = preprocess(test_features)\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "train_targets = train_targets.loc[train_data['cp_type']==0].reset_index(drop=True)\n",
    "train_data = train_data.loc[train_data['cp_type']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "def get_tail_labels(df: pd.DataFrame, ql=[0.03, 1.]) -> list:\n",
    "    \" Find the underepresented targets a.k.a. minority labels. \"\n",
    "    irlbl = df.sum(axis=0)\n",
    "    irlbl = irlbl[(irlbl > irlbl.quantile(ql[0])) & ((irlbl < irlbl.quantile(ql[1])))]  # Filtering\n",
    "    irlbl = irlbl.max() / irlbl\n",
    "    threshold_irlbl = irlbl.median()\n",
    "    tail_labels = irlbl[irlbl > threshold_irlbl].index.tolist()\n",
    "    return tail_labels\n",
    "\n",
    "def get_minority_samples(X: pd.DataFrame, y: pd.DataFrame, ql=[0.03, 1.]):\n",
    "    \" Find minority samples associated with minority labels. \"\n",
    "    tail_labels = get_tail_labels(y, ql=ql)\n",
    "    index = y[y[tail_labels].apply(lambda x: (x == 1).any(), axis=1)].index.tolist()\n",
    "    \n",
    "    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n",
    "    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n",
    "    return X_sub, y_sub\n",
    "\n",
    "def nearest_neighbour(X: pd.DataFrame, neigh) -> list:\n",
    "    \" Find nearest neighbors for each sample in X dataframe. \"\n",
    "    nbs = NearestNeighbors(n_neighbors=neigh, metric='euclidean', algorithm='kd_tree').fit(X)\n",
    "    euclidean, indices = nbs.kneighbors(X)\n",
    "    return indices\n",
    "\n",
    "def MLSMOTE(X, y, n_samples, n_neighbors=5):\n",
    "    \" Generate new samples using MLSMOTE algorithm. \"\n",
    "    indices2 = nearest_neighbour(X, neigh=n_neighbors)\n",
    "    n = len(indices2)\n",
    "    new_X = np.zeros((n_samples, X.shape[1]))\n",
    "    target = np.zeros((n_samples, y.shape[1]))\n",
    "    for i in range(n_samples):\n",
    "        reference = random.randint(0, n-1)\n",
    "        neighbor = random.choice(indices2[reference, 1:])\n",
    "        all_point = indices2[reference]\n",
    "        nn_df = y[y.index.isin(all_point)]\n",
    "        ser = nn_df.sum(axis = 0, skipna = True)\n",
    "        target[i] = np.array([1 if val > 0 else 0 for val in ser])\n",
    "        ratio = random.random()\n",
    "        gap = X.loc[reference,:] - X.loc[neighbor,:]\n",
    "        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n",
    "    new_X = pd.DataFrame(new_X, columns=X.columns)\n",
    "    target = pd.DataFrame(target, columns=y.columns)\n",
    "    return new_X, target\n",
    "\n",
    "def augment_data(X, y, oversample_args: tuple):\n",
    "    \" Augment feature/targets data (just doing oversampling for now)\"\n",
    "    n_samples, n_neighbors = oversample_args\n",
    "\n",
    "    X_sub, y_sub = get_minority_samples(X, y)\n",
    "    X_res, y_res = MLSMOTE(X_sub, y_sub, n_samples, n_neighbors)\n",
    "    X_augmented = pd.concat([X, X_res])\n",
    "    y_augmented = pd.concat([y, y_res])\n",
    "    return X_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oversample_args = (1000, 5)\n",
    "train_data_augmented, train_targets_augmented = augment_data(train_data, train_targets, data_oversample_args)\n",
    "\n",
    "X = train_data_augmented.values\n",
    "Y = train_targets_augmented.values\n",
    "X_test = test_data.values\n",
    "\n",
    "X_original = train_data.values\n",
    "Y_original = train_targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embeddings': ['none'],\n",
       " 'lr_scheduler': ['cosine_annealing', 'plateau'],\n",
       " 'networks': ['shapedresnet'],\n",
       " 'preprocessors': ['none', 'truncated_svd', 'power_transformer'],\n",
       " 'result_logger_dir': 'logs/',\n",
       " 'log_level': 'warning',\n",
       " 'hyperparameter_search_space_updates': None,\n",
       " 'categorical_features': None,\n",
       " 'dataset_name': None,\n",
       " 'run_id': '0',\n",
       " 'task_id': -1,\n",
       " 'algorithm': 'bohb',\n",
       " 'portfolio_type': 'greedy',\n",
       " 'budget_type': 'time',\n",
       " 'eta': 3,\n",
       " 'min_workers': 1,\n",
       " 'working_dir': '.',\n",
       " 'network_interface_name': 'eth0',\n",
       " 'memory_limit_mb': 1000000,\n",
       " 'use_tensorboard_logger': False,\n",
       " 'run_worker_on_master_node': True,\n",
       " 'use_pynisher': True,\n",
       " 'validation_split': 0.3,\n",
       " 'refit_validation_split': 0.0,\n",
       " 'cross_validator': 'none',\n",
       " 'cross_validator_args': {},\n",
       " 'min_budget_for_cv': 0,\n",
       " 'shuffle': True,\n",
       " 'imputation_strategies': ['mean', 'median', 'most_frequent'],\n",
       " 'normalization_strategies': ['none', 'minmax', 'standardize', 'maxabs'],\n",
       " 'over_sampling_methods': ['none'],\n",
       " 'under_sampling_methods': ['none'],\n",
       " 'target_size_strategies': ['none'],\n",
       " 'final_activation': 'sigmoid',\n",
       " 'initialization_methods': ['default', 'sparse'],\n",
       " 'initializer': 'simple_initializer',\n",
       " 'optimizer': ['adam', 'adamw', 'sgd', 'rmsprop'],\n",
       " 'additional_logs': [],\n",
       " 'optimize_metric': 'multilabel_accuracy',\n",
       " 'additional_metrics': [],\n",
       " 'loss_modules': ['bce_with_logits', 'bce_with_logits_weighted'],\n",
       " 'batch_loss_computation_techniques': ['standard', 'mixup'],\n",
       " 'cuda': True,\n",
       " 'torch_num_threads': 1,\n",
       " 'full_eval_each_epoch': False,\n",
       " 'best_over_epochs': False,\n",
       " 'save_models': False,\n",
       " 'predict_model': None,\n",
       " 'early_stopping_patience': inf,\n",
       " 'early_stopping_reset_parameters': False,\n",
       " 'random_seed': 3425318595,\n",
       " 'min_budget': 120,\n",
       " 'max_budget': 6000,\n",
       " 'max_runtime': 24000,\n",
       " 'num_iterations': inf}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autonet = AutoNetMultilabel(config_preset=\"medium_cs\", result_logger_dir=\"logs/\")\n",
    "autonet.get_current_autonet_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2995: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:603: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:603: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:484: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:2995: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:603: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "results_fit = autonet.fit(X_train=X,\n",
    "                          Y_train=Y,\n",
    "                          validation_split=0.3,\n",
    "                          max_runtime=300,\n",
    "                          min_budget=60,\n",
    "                          max_budget=100,\n",
    "                          refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logs/results_fit.json\", \"w\") as file:\n",
    "    json.dump(results_fit, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score:  0.02341899034080554\n"
     ]
    }
   ],
   "source": [
    "score = autonet.score(X_test=X_original, Y_test=Y_original)\n",
    "print(\"Model accuracy score: \", score)\n",
    "# TODO: what does this score represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = autonet.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 5.2453688e-36, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [1.1269496e-03, 5.0480483e-04, 9.7554994e-13, ..., 3.5363615e-10,\n",
       "        8.7857707e-12, 8.7715181e-13],\n",
       "       ...,\n",
       "       [1.1358051e-16, 8.5846139e-14, 1.2323135e-14, ..., 5.0025088e-15,\n",
       "        4.7446711e-15, 1.1774521e-15],\n",
       "       [3.7844887e-13, 9.3131940e-11, 1.3905371e-09, ..., 2.5447855e-10,\n",
       "        2.3934350e-09, 1.2638107e-10],\n",
       "       [1.5752066e-25, 9.4785180e-21, 5.2640633e-24, ..., 4.6327245e-24,\n",
       "        2.2442925e-25, 8.3291474e-25]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [col for col in train_targets.columns]\n",
    "sample_submission[targets] = preds\n",
    "sample_submission.loc[test_features['cp_type']=='ctl_vehicle', targets] = 0\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, features, targets, mode=\"train\"):\n",
    "        self.mode = mode\n",
    "        self.data = features\n",
    "        if mode == \"train\":\n",
    "            self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"train\":\n",
    "            return torch.FloatTensor(self.data[idx]), torch.FloatTensor(\n",
    "                self.targets[idx]\n",
    "            )\n",
    "        elif self.mode == \"eval\":\n",
    "            return torch.FloatTensor(self.data[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, device, data_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for inputs, _ in data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        preds.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9ab060d266cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 4096\n",
    "test_dataset = MoaDataset(X_test, None, mode='eval')\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "preds = predict(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
